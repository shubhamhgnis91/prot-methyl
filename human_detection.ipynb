{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cccf716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5e3dd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded positive data: (987, 5)\n",
      "Successfully loaded negative data: (56708, 5)\n",
      "\n",
      "Positive Data Columns: ['Entry', 'Organism', 'Modified residue', 'Modified_position', 'Positive_sequence']\n",
      "Negative Data Columns: ['Entry', 'Organism', 'Modified residue', 'Negative_R_position', 'Negative_sequence']\n"
     ]
    }
   ],
   "source": [
    "# Define the directory containing your data\n",
    "DATA_DIR = \"data/Human/Omega-N-methylarginine/\" # MODIFY if your path is different\n",
    "\n",
    "# Define the exact filenames for your simplified CSVs\n",
    "POS_FILE = os.path.join(DATA_DIR, \"human_positive_omega-n-methylarginine_sequences.csv\") # Or your positive filename\n",
    "NEG_FILE = os.path.join(DATA_DIR, \"human_negative_omega-n-methylarginine_sequences.csv\") # Or your negative filename\n",
    "\n",
    "try:\n",
    "    # Load positive data, potentially skipping the unnamed index column if present\n",
    "    positive_df_raw = pd.read_csv(POS_FILE)\n",
    "    if positive_df_raw.columns[0].startswith('Unnamed'):\n",
    "         positive_df_raw = pd.read_csv(POS_FILE, index_col=0)\n",
    "\n",
    "    # Load negative data\n",
    "    negative_df_raw = pd.read_csv(NEG_FILE)\n",
    "    if negative_df_raw.columns[0].startswith('Unnamed'):\n",
    "         negative_df_raw = pd.read_csv(NEG_FILE, index_col=0)\n",
    "\n",
    "    print(f\"Successfully loaded positive data: {positive_df_raw.shape}\")\n",
    "    print(f\"Successfully loaded negative data: {negative_df_raw.shape}\")\n",
    "    print(\"\\nPositive Data Columns:\", positive_df_raw.columns.tolist())\n",
    "    print(\"Negative Data Columns:\", negative_df_raw.columns.tolist())\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading file: {e}\")\n",
    "    print(f\"Ensure the CSV files exist in the specified path: '{DATA_DIR}'\")\n",
    "    # exit() # Or handle error appropriately in a notebook\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during loading: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef16770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing and cleaning data...\n",
      "Positive data prepared. Shape: (987, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing and cleaning data...\")\n",
    "\n",
    "pos_seq_col_raw = 'Positive_sequence' # Column containing the positive sequence\n",
    "if pos_seq_col_raw not in positive_df_raw.columns:\n",
    "    raise ValueError(f\"Column '{pos_seq_col_raw}' not found in positive data.\")\n",
    "\n",
    "positive_data = positive_df_raw[[pos_seq_col_raw]].copy() # Keep only the sequence column for now\n",
    "positive_data.rename(columns={pos_seq_col_raw: 'Sequence'}, inplace=True)\n",
    "print(f\"Positive data prepared. Shape: {positive_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4463e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative data prepared. Shape: (56708, 1)\n"
     ]
    }
   ],
   "source": [
    "neg_seq_col_raw = 'Negative_sequence' # Column containing the negative sequence\n",
    "if neg_seq_col_raw not in negative_df_raw.columns:\n",
    "     raise ValueError(f\"Column '{neg_seq_col_raw}' not found in negative data.\")\n",
    "\n",
    "negative_data = negative_df_raw[[neg_seq_col_raw]].copy() # Keep only the sequence column for now\n",
    "negative_data.rename(columns={neg_seq_col_raw: 'Sequence'}, inplace=True)\n",
    "print(f\"Negative data prepared. Shape: {negative_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00a792b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample positive data after prep:\n",
      "      Sequence  Length\n",
      "0  YQKAARGGGAA      11\n",
      "1  RAPGPRGSYLG      11\n",
      "2  GYSAGRGIYSR      11\n",
      "3  STKRGRGGGEA      11\n",
      "4  CSLEIRKPGPF      11\n",
      "\n",
      "Sample negative data after prep:\n",
      "      Sequence  Length\n",
      "0  LALMERTGYSM      11\n",
      "1  QENGQRKYGGP      11\n",
      "2  GPHPQRGCEVF      11\n",
      "3  VGKIPRDVYED      11\n",
      "4  FEAVGRIYELR      11\n"
     ]
    }
   ],
   "source": [
    "# Add length column to both dataframes for filtering\n",
    "positive_data['Length'] = positive_data['Sequence'].astype(str).str.len()\n",
    "negative_data['Length'] = negative_data['Sequence'].astype(str).str.len()\n",
    "\n",
    "print(\"\\nSample positive data after prep:\")\n",
    "print(positive_data.head())\n",
    "print(\"\\nSample negative data after prep:\")\n",
    "print(negative_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c27ad77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YQKAARGGGAA</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RAPGPRGSYLG</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GYSAGRGIYSR</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sequence  Length\n",
       "0  YQKAARGGGAA      11\n",
       "1  RAPGPRGSYLG      11\n",
       "2  GYSAGRGIYSR      11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96af75ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LALMERTGYSM</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QENGQRKYGGP</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPHPQRGCEVF</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sequence  Length\n",
       "0  LALMERTGYSM      11\n",
       "1  QENGQRKYGGP      11\n",
       "2  GPHPQRGCEVF      11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "403c2b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive one hot shape: (11, 20)\n",
      "Negative one hot shape: (11, 20)\n"
     ]
    }
   ],
   "source": [
    "# Standard amino acids (canonical 20) in fixed order.\n",
    "amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\")  # This order is fixed for all sequences.\n",
    "aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "\n",
    "def one_hot_encode(sequence, aa_to_index):\n",
    "\n",
    "    # Initialize a zero matrix for one-hot encoding.\n",
    "    encoding = np.zeros((len(sequence), len(aa_to_index)), dtype=int)\n",
    "    for i, aa in enumerate(sequence):\n",
    "        encoding[i, aa_to_index[aa]] = 1\n",
    "    return encoding\n",
    "\n",
    "# Apply one-hot encoding to the positive sequences.\n",
    "positive_data['one_hot'] = positive_data['Sequence'].apply(lambda seq: one_hot_encode(seq, aa_to_index))\n",
    "# Print the shape of one hot encoding for the first positive sequence.\n",
    "print(\"Positive one hot shape:\", positive_data['one_hot'].iloc[0].shape)\n",
    "\n",
    "# Apply one-hot encoding to the negative sequences.\n",
    "negative_data['one_hot'] = negative_data['Sequence'].apply(lambda seq: one_hot_encode(seq, aa_to_index))\n",
    "# Print the shape of one hot encoding for the first negative sequence.\n",
    "print(\"Negative one hot shape:\", negative_data['one_hot'].iloc[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d00cf7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "\n",
    "# Define a function to calculate Shannon entropy for a sequence.\n",
    "def shannon_entropy(sequence):\n",
    "    \"\"\"\n",
    "    Calculate the Shannon entropy of a given amino acid sequence.\n",
    "    \"\"\"\n",
    "    length = len(sequence)\n",
    "    # Count frequency of each amino acid in the sequence.\n",
    "    counts = {}\n",
    "    for aa in sequence:\n",
    "        counts[aa] = counts.get(aa, 0) + 1\n",
    "    \n",
    "    # Compute entropy.\n",
    "    entropy = 0.0\n",
    "    for count in counts.values():\n",
    "        p = count / length\n",
    "        entropy -= p * log2(p)\n",
    "    return entropy\n",
    "\n",
    "# Apply the function to create a new feature column for both datasets.\n",
    "positive_data['shannon_entropy'] = positive_data['Sequence'].apply(shannon_entropy)\n",
    "negative_data['shannon_entropy'] = negative_data['Sequence'].apply(shannon_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b07261e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive TF-IDF feature shape: (20,)\n",
      "Negative TF-IDF feature shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "all_sequences = pd.concat([positive_data['Sequence'], negative_data['Sequence']])\n",
    "\n",
    "# 2. Define the TF-IDF vectorizer for character-level features.\n",
    "#    Using analyzer='char' and ngram_range=(1,1) ensures each amino acid is treated as a separate feature.\n",
    "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "vectorizer.fit(all_sequences)\n",
    "\n",
    "# 3. Transform the sequences in each dataframe.\n",
    "positive_tfidf = vectorizer.transform(positive_data['Sequence'])\n",
    "negative_tfidf = vectorizer.transform(negative_data['Sequence'])\n",
    "\n",
    "# 4. Convert the TF-IDF sparse matrices to dense arrays and add as a new column in the dataframes.\n",
    "#    Each element in the new column 'tfidf' is a vector standardized based on the common vocabulary.\n",
    "positive_data['tfidf'] = list(positive_tfidf.toarray())\n",
    "negative_data['tfidf'] = list(negative_tfidf.toarray())\n",
    "\n",
    "# Print the shape of the first TF-IDF feature in each dataframe.\n",
    "print(\"Positive TF-IDF feature shape:\", positive_data['tfidf'].iloc[0].shape)\n",
    "print(\"Negative TF-IDF feature shape:\", negative_data['tfidf'].iloc[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a4468cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive DPC feature shape: (400,)\n",
      "Negative DPC feature shape: (400,)\n"
     ]
    }
   ],
   "source": [
    "amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "num_dipeptides = len(amino_acids) * len(amino_acids)  # 400\n",
    "\n",
    "def dipeptide_composition(sequence, aa_to_index):\n",
    "    \"\"\"\n",
    "    Calculate the dipeptide composition for a given sequence.\n",
    "    Returns a 400-dimensional vector where each element is the normalized count\n",
    "    of the corresponding dipeptide.\n",
    "    \"\"\"\n",
    "    comp = np.zeros(num_dipeptides, dtype=float)\n",
    "    n = len(sequence)\n",
    "    if n < 2:\n",
    "        return comp  # Not enough characters for a dipeptide.\n",
    "    \n",
    "    total_dipeptides = n - 1\n",
    "    for i in range(total_dipeptides):\n",
    "        aa1 = sequence[i]\n",
    "        aa2 = sequence[i+1]\n",
    "        if aa1 in aa_to_index and aa2 in aa_to_index:\n",
    "            idx = aa_to_index[aa1] * len(aa_to_index) + aa_to_index[aa2]\n",
    "            comp[idx] += 1\n",
    "        else:\n",
    "            # Handle unknown characters if necessary.\n",
    "            continue\n",
    "    # Normalize the vector so that the sum equals 1 (frequency distribution).\n",
    "    comp = comp / total_dipeptides\n",
    "    return comp\n",
    "\n",
    "# Apply the function to the positive sequences.\n",
    "positive_data['dpc'] = positive_data['Sequence'].apply(lambda seq: dipeptide_composition(seq, aa_to_index))\n",
    "# Print the shape of the DPC vector for the first positive sequence.\n",
    "print(\"Positive DPC feature shape:\", positive_data['dpc'].iloc[0].shape)\n",
    "\n",
    "# Apply the function to the negative sequences.\n",
    "negative_data['dpc'] = negative_data['Sequence'].apply(lambda seq: dipeptide_composition(seq, aa_to_index))\n",
    "# Print the shape of the DPC vector for the first negative sequence.\n",
    "print(\"Negative DPC feature shape:\", negative_data['dpc'].iloc[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "090d6f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive PseAAC feature shape: (25,)\n",
      "Negative PseAAC feature shape: (25,)\n"
     ]
    }
   ],
   "source": [
    "def compute_pseaac(sequence, lambda_value=5, w=0.05):\n",
    "    \n",
    "    # Define the canonical amino acids and filter the sequence.\n",
    "    aa_list = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    valid_set = set(aa_list)\n",
    "    seq = ''.join([aa for aa in sequence.upper() if aa in valid_set])\n",
    "    L = len(seq)\n",
    "    if L == 0:\n",
    "        return np.array([np.nan]*(20+lambda_value))\n",
    "    \n",
    "    # Conventional Amino Acid Composition (AAC): 20 features.\n",
    "    AAC = np.zeros(20)\n",
    "    for aa in seq:\n",
    "        idx = aa_list.index(aa)\n",
    "        AAC[idx] += 1\n",
    "    AAC = AAC / L  # normalize by sequence length\n",
    "\n",
    "    # Define three physicochemical properties.\n",
    "    # 1. Hydrophobicity (using a common scale)\n",
    "    hydrophobicity = {\n",
    "        'A': 0.62, 'R': -2.53, 'N': -0.78, 'D': -0.90, 'C': 0.29,\n",
    "        'E': -0.74, 'Q': -0.85, 'G': 0.48, 'H': -0.40, 'I': 1.38,\n",
    "        'L': 1.06, 'K': -1.50, 'M': 0.64, 'F': 1.19, 'P': 0.12,\n",
    "        'S': -0.18, 'T': -0.05, 'W': 0.81, 'Y': 0.26, 'V': 1.08\n",
    "    }\n",
    "    # 2. Hydrophilicity (using the Hopp-Woods scale)\n",
    "    hydrophilicity = {\n",
    "        'A': -0.5, 'R': 3.0, 'N': 0.2, 'D': 3.0, 'C': -1.0,\n",
    "        'E': 3.0, 'Q': 0.2, 'G': 0.0, 'H': -0.5, 'I': -1.8,\n",
    "        'L': -1.8, 'K': 3.0, 'M': -1.3, 'F': -2.5, 'P': 0.0,\n",
    "        'S': 0.3, 'T': -0.4, 'W': -3.4, 'Y': -2.3, 'V': -1.5\n",
    "    }\n",
    "    # 3. Side-chain mass (approximate molecular weights)\n",
    "    mass = {\n",
    "        'A': 89.09, 'R': 174.20, 'N': 132.12, 'D': 133.10, 'C': 121.15,\n",
    "        'E': 147.13, 'Q': 146.15, 'G': 75.07, 'H': 155.16, 'I': 131.17,\n",
    "        'L': 131.17, 'K': 146.19, 'M': 149.21, 'F': 165.19, 'P': 115.13,\n",
    "        'S': 105.09, 'T': 119.12, 'W': 204.23, 'Y': 181.19, 'V': 117.15\n",
    "    }\n",
    "    \n",
    "    # Helper function: Normalize a property dictionary.\n",
    "    def normalize_property(prop_dict):\n",
    "        values = np.array([prop_dict[aa] for aa in aa_list])\n",
    "        mean = np.mean(values)\n",
    "        std = np.std(values)\n",
    "        return {aa: (prop_dict[aa] - mean) / std for aa in aa_list}\n",
    "\n",
    "    norm_hydro = normalize_property(hydrophobicity)\n",
    "    norm_hphil = normalize_property(hydrophilicity)\n",
    "    norm_mass  = normalize_property(mass)\n",
    "    \n",
    "    # Compute sequence-order correlation factors theta for lags 1 to lambda_value.\n",
    "    theta = np.zeros(lambda_value)\n",
    "    if L <= 1:\n",
    "        theta = np.zeros(lambda_value)\n",
    "    else:\n",
    "        for l in range(1, lambda_value+1):\n",
    "            if L - l <= 0:\n",
    "                theta[l-1] = 0\n",
    "            else:\n",
    "                sum_corr = 0.0\n",
    "                for i in range(L - l):\n",
    "                    diff1 = norm_hydro[seq[i]] - norm_hydro[seq[i+l]]\n",
    "                    diff2 = norm_hphil[seq[i]] - norm_hphil[seq[i+l]]\n",
    "                    diff3 = norm_mass[seq[i]] - norm_mass[seq[i+l]]\n",
    "                    sum_corr += (diff1**2 + diff2**2 + diff3**2) / 3.0\n",
    "                theta[l-1] = sum_corr / (L - l)\n",
    "    \n",
    "    # Calculate the normalization factor.\n",
    "    norm_factor = 1 + w * np.sum(theta)\n",
    "    \n",
    "    # Construct the PseAAC vector: first 20 are AAC, next lambda_value are the theta terms.\n",
    "    pseaac_vector = np.concatenate((AAC / norm_factor, (w * theta / norm_factor)))\n",
    "    return pseaac_vector\n",
    "\n",
    "\n",
    "positive_data['pseaac'] = positive_data['Sequence'].apply(lambda seq: compute_pseaac(seq, lambda_value=5, w=0.05))\n",
    "negative_data['pseaac'] = negative_data['Sequence'].apply(lambda seq: compute_pseaac(seq, lambda_value=5, w=0.05))\n",
    "\n",
    "# Print the shape of the first PseAAC feature in each dataframe.\n",
    "print(\"Positive PseAAC feature shape:\", positive_data['pseaac'].iloc[0].shape)\n",
    "print(\"Negative PseAAC feature shape:\", negative_data['pseaac'].iloc[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "950831c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_vector(seq_features):\n",
    "    \n",
    "    # Extract and flatten each feature:\n",
    "    # 1. One-hot: a 2D array; flatten it.\n",
    "    one_hot_vec = np.array(seq_features['one_hot']).flatten()\n",
    "    \n",
    "    # 2. Shannon entropy: scalar -> convert to 1D array.\n",
    "    shannon_vec = np.array([seq_features['shannon_entropy']])\n",
    "    \n",
    "    # 3. TF-IDF: assume already a vector.\n",
    "    tfidf_vec = np.array(seq_features['tfidf'])\n",
    "    \n",
    "    # 4. Dipeptide Composition (DPC): vector.\n",
    "    dpc_vec = np.array(seq_features['dpc'])\n",
    "    \n",
    "    # 5. PseAAC: vector.\n",
    "    pseaac_vec = np.array(seq_features['pseaac'])     \n",
    "    \n",
    "    combined_vector = np.concatenate([one_hot_vec, shannon_vec, tfidf_vec, dpc_vec, pseaac_vec])\n",
    "\n",
    "\n",
    "    total_length = combined_vector.shape[0]\n",
    "    vector_height = int(np.ceil(total_length / 64))\n",
    "\n",
    "    padded_length = vector_height * 64\n",
    "\n",
    "    padded_vector = np.pad(combined_vector, (0, padded_length - total_length), mode='constant', constant_values=0)\n",
    "\n",
    "    vector = padded_vector.reshape((vector_height, 64))\n",
    "\n",
    "    pad_height = 64 - vector.shape[0]\n",
    "    pad_width = 64 - vector.shape[1]\n",
    "\n",
    "    pad_top = pad_height // 2\n",
    "    pad_bottom = pad_height - pad_top\n",
    "    pad_left = pad_width // 2\n",
    "    pad_right = pad_width - pad_left\n",
    "\n",
    "    padded_vector = np.pad(vector, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant', constant_values=0)\n",
    "    \n",
    "    return padded_vector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df76fb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive vector shape: (64, 64)\n",
      "Negative vector shape: (64, 64)\n"
     ]
    }
   ],
   "source": [
    "# Lists to store the feature images for positive and negative sequences.\n",
    "positive_vector = []\n",
    "negative_vector = []\n",
    "\n",
    "# Loop over each row in the positive_data dataframe.\n",
    "for index, row in positive_data.iterrows():\n",
    "    seq_features = {\n",
    "        'one_hot': row['one_hot'],\n",
    "        'shannon_entropy': row['shannon_entropy'],\n",
    "        'tfidf': row['tfidf'],\n",
    "        'dpc': row['dpc'],\n",
    "        'pseaac': row['pseaac']\n",
    "    }\n",
    "    img = create_feature_vector(seq_features)  # You can adjust image_width as needed.\n",
    "    positive_vector.append(img)\n",
    "\n",
    "\n",
    "# Loop over each row in the negative_data dataframe.\n",
    "for index, row in negative_data.iterrows():\n",
    "    seq_features = {\n",
    "        'one_hot': row['one_hot'],\n",
    "        'shannon_entropy': row['shannon_entropy'],\n",
    "        'tfidf': row['tfidf'],\n",
    "        'dpc': row['dpc'],\n",
    "        'pseaac': row['pseaac']\n",
    "    }\n",
    "    img = create_feature_vector(seq_features)\n",
    "    negative_vector.append(img)\n",
    "\n",
    "# Print the shape of one sample image from each list for verification.\n",
    "print(\"Positive vector shape:\", positive_vector[0].shape)\n",
    "print(\"Negative vector shape:\", negative_vector[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "514d33b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(987, 56708)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_vector), len(negative_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b46c2b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_labels = np.ones(len(positive_vector))\n",
    "neg_labels = np.zeros(len(negative_vector))\n",
    "\n",
    "\n",
    "X = np.vstack([positive_vector, negative_vector])\n",
    "y = np.concatenate([pos_labels, neg_labels])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b6fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive samples: 987\n",
      "Total negative samples: 56708\n",
      "Created 58 folds for negatives (each of size ~987).\n",
      "\n",
      "Processing fold 1/58 with 987 negative samples...\n",
      "Fold 1 - SVM: Accuracy: 0.790, Precision: 0.831, Recall: 0.726, F1: 0.775, MCC: 0.584\n",
      "Fold 1 - RandomForest: Accuracy: 0.767, Precision: 0.790, Recall: 0.726, F1: 0.757, MCC: 0.536\n",
      "Fold 1 - KNN: Accuracy: 0.706, Precision: 0.687, Recall: 0.756, F1: 0.720, MCC: 0.415\n",
      "Fold 1 - MLP: Accuracy: 0.772, Precision: 0.802, Recall: 0.721, F1: 0.759, MCC: 0.547\n",
      "\n",
      "Processing fold 2/58 with 987 negative samples...\n",
      "Fold 2 - SVM: Accuracy: 0.737, Precision: 0.736, Recall: 0.736, F1: 0.736, MCC: 0.473\n",
      "Fold 2 - RandomForest: Accuracy: 0.722, Precision: 0.723, Recall: 0.716, F1: 0.719, MCC: 0.443\n",
      "Fold 2 - KNN: Accuracy: 0.706, Precision: 0.667, Recall: 0.822, F1: 0.736, MCC: 0.425\n",
      "Fold 2 - MLP: Accuracy: 0.714, Precision: 0.698, Recall: 0.751, F1: 0.724, MCC: 0.429\n",
      "\n",
      "Processing fold 3/58 with 987 negative samples...\n",
      "Fold 3 - SVM: Accuracy: 0.752, Precision: 0.780, Recall: 0.701, F1: 0.738, MCC: 0.506\n",
      "Fold 3 - RandomForest: Accuracy: 0.719, Precision: 0.744, Recall: 0.665, F1: 0.702, MCC: 0.440\n",
      "Fold 3 - KNN: Accuracy: 0.694, Precision: 0.662, Recall: 0.787, F1: 0.719, MCC: 0.395\n",
      "Fold 3 - MLP: Accuracy: 0.716, Precision: 0.723, Recall: 0.701, F1: 0.711, MCC: 0.433\n",
      "\n",
      "Processing fold 4/58 with 987 negative samples...\n",
      "Fold 4 - SVM: Accuracy: 0.734, Precision: 0.750, Recall: 0.701, F1: 0.724, MCC: 0.469\n",
      "Fold 4 - RandomForest: Accuracy: 0.737, Precision: 0.757, Recall: 0.695, F1: 0.725, MCC: 0.475\n",
      "Fold 4 - KNN: Accuracy: 0.678, Precision: 0.647, Recall: 0.782, F1: 0.708, MCC: 0.365\n",
      "Fold 4 - MLP: Accuracy: 0.709, Precision: 0.711, Recall: 0.701, F1: 0.706, MCC: 0.418\n",
      "\n",
      "Processing fold 5/58 with 987 negative samples...\n",
      "Fold 5 - SVM: Accuracy: 0.777, Precision: 0.811, Recall: 0.721, F1: 0.763, MCC: 0.558\n",
      "Fold 5 - RandomForest: Accuracy: 0.792, Precision: 0.821, Recall: 0.746, F1: 0.782, MCC: 0.587\n",
      "Fold 5 - KNN: Accuracy: 0.737, Precision: 0.700, Recall: 0.827, F1: 0.758, MCC: 0.482\n",
      "Fold 5 - MLP: Accuracy: 0.732, Precision: 0.754, Recall: 0.685, F1: 0.718, MCC: 0.465\n",
      "\n",
      "Processing fold 6/58 with 987 negative samples...\n",
      "Fold 6 - SVM: Accuracy: 0.734, Precision: 0.756, Recall: 0.690, F1: 0.721, MCC: 0.470\n",
      "Fold 6 - RandomForest: Accuracy: 0.747, Precision: 0.754, Recall: 0.731, F1: 0.742, MCC: 0.494\n",
      "Fold 6 - KNN: Accuracy: 0.696, Precision: 0.665, Recall: 0.787, F1: 0.721, MCC: 0.399\n",
      "Fold 6 - MLP: Accuracy: 0.722, Precision: 0.719, Recall: 0.726, F1: 0.722, MCC: 0.443\n",
      "\n",
      "Processing fold 7/58 with 987 negative samples...\n",
      "Fold 7 - SVM: Accuracy: 0.757, Precision: 0.789, Recall: 0.701, F1: 0.742, MCC: 0.517\n",
      "Fold 7 - RandomForest: Accuracy: 0.752, Precision: 0.796, Recall: 0.675, F1: 0.731, MCC: 0.510\n",
      "Fold 7 - KNN: Accuracy: 0.696, Precision: 0.656, Recall: 0.822, F1: 0.730, MCC: 0.406\n",
      "Fold 7 - MLP: Accuracy: 0.729, Precision: 0.737, Recall: 0.711, F1: 0.724, MCC: 0.458\n",
      "\n",
      "Processing fold 8/58 with 987 negative samples...\n",
      "Fold 8 - SVM: Accuracy: 0.775, Precision: 0.818, Recall: 0.706, F1: 0.757, MCC: 0.554\n",
      "Fold 8 - RandomForest: Accuracy: 0.777, Precision: 0.819, Recall: 0.711, F1: 0.761, MCC: 0.559\n",
      "Fold 8 - KNN: Accuracy: 0.739, Precision: 0.716, Recall: 0.792, F1: 0.752, MCC: 0.481\n",
      "Fold 8 - MLP: Accuracy: 0.732, Precision: 0.763, Recall: 0.670, F1: 0.714, MCC: 0.467\n",
      "\n",
      "Processing fold 9/58 with 987 negative samples...\n",
      "Fold 9 - SVM: Accuracy: 0.752, Precision: 0.765, Recall: 0.726, F1: 0.745, MCC: 0.504\n",
      "Fold 9 - RandomForest: Accuracy: 0.737, Precision: 0.763, Recall: 0.685, F1: 0.722, MCC: 0.476\n",
      "Fold 9 - KNN: Accuracy: 0.729, Precision: 0.691, Recall: 0.827, F1: 0.753, MCC: 0.468\n",
      "Fold 9 - MLP: Accuracy: 0.727, Precision: 0.738, Recall: 0.701, F1: 0.719, MCC: 0.454\n",
      "\n",
      "Processing fold 10/58 with 987 negative samples...\n",
      "Fold 10 - SVM: Accuracy: 0.765, Precision: 0.783, Recall: 0.731, F1: 0.756, MCC: 0.530\n",
      "Fold 10 - RandomForest: Accuracy: 0.744, Precision: 0.767, Recall: 0.701, F1: 0.732, MCC: 0.490\n",
      "Fold 10 - KNN: Accuracy: 0.709, Precision: 0.669, Recall: 0.822, F1: 0.738, MCC: 0.429\n",
      "Fold 10 - MLP: Accuracy: 0.734, Precision: 0.747, Recall: 0.706, F1: 0.726, MCC: 0.469\n",
      "\n",
      "Processing fold 11/58 with 987 negative samples...\n",
      "Fold 11 - SVM: Accuracy: 0.747, Precision: 0.759, Recall: 0.721, F1: 0.740, MCC: 0.494\n",
      "Fold 11 - RandomForest: Accuracy: 0.729, Precision: 0.745, Recall: 0.695, F1: 0.719, MCC: 0.459\n",
      "Fold 11 - KNN: Accuracy: 0.709, Precision: 0.674, Recall: 0.807, F1: 0.734, MCC: 0.426\n",
      "Fold 11 - MLP: Accuracy: 0.699, Precision: 0.707, Recall: 0.675, F1: 0.691, MCC: 0.398\n",
      "\n",
      "Processing fold 12/58 with 987 negative samples...\n",
      "Fold 12 - SVM: Accuracy: 0.792, Precision: 0.840, Recall: 0.721, F1: 0.776, MCC: 0.591\n",
      "Fold 12 - RandomForest: Accuracy: 0.790, Precision: 0.843, Recall: 0.711, F1: 0.771, MCC: 0.587\n",
      "Fold 12 - KNN: Accuracy: 0.739, Precision: 0.714, Recall: 0.797, F1: 0.753, MCC: 0.482\n",
      "Fold 12 - MLP: Accuracy: 0.754, Precision: 0.781, Recall: 0.706, F1: 0.741, MCC: 0.511\n",
      "\n",
      "Processing fold 13/58 with 987 negative samples...\n",
      "Fold 13 - SVM: Accuracy: 0.754, Precision: 0.772, Recall: 0.721, F1: 0.745, MCC: 0.510\n",
      "Fold 13 - RandomForest: Accuracy: 0.772, Precision: 0.792, Recall: 0.736, F1: 0.763, MCC: 0.546\n",
      "Fold 13 - KNN: Accuracy: 0.724, Precision: 0.704, Recall: 0.772, F1: 0.736, MCC: 0.450\n",
      "Fold 13 - MLP: Accuracy: 0.757, Precision: 0.779, Recall: 0.716, F1: 0.746, MCC: 0.516\n",
      "\n",
      "Processing fold 14/58 with 987 negative samples...\n",
      "Fold 14 - SVM: Accuracy: 0.742, Precision: 0.760, Recall: 0.706, F1: 0.732, MCC: 0.485\n",
      "Fold 14 - RandomForest: Accuracy: 0.739, Precision: 0.745, Recall: 0.726, F1: 0.735, MCC: 0.479\n",
      "Fold 14 - KNN: Accuracy: 0.719, Precision: 0.684, Recall: 0.812, F1: 0.742, MCC: 0.446\n",
      "Fold 14 - MLP: Accuracy: 0.686, Precision: 0.699, Recall: 0.650, F1: 0.674, MCC: 0.373\n",
      "\n",
      "Processing fold 15/58 with 987 negative samples...\n",
      "Fold 15 - SVM: Accuracy: 0.744, Precision: 0.770, Recall: 0.695, F1: 0.731, MCC: 0.491\n",
      "Fold 15 - RandomForest: Accuracy: 0.742, Precision: 0.754, Recall: 0.716, F1: 0.734, MCC: 0.484\n",
      "Fold 15 - KNN: Accuracy: 0.727, Precision: 0.694, Recall: 0.807, F1: 0.746, MCC: 0.459\n",
      "Fold 15 - MLP: Accuracy: 0.729, Precision: 0.737, Recall: 0.711, F1: 0.724, MCC: 0.458\n",
      "\n",
      "Processing fold 16/58 with 987 negative samples...\n",
      "Fold 16 - SVM: Accuracy: 0.787, Precision: 0.834, Recall: 0.716, F1: 0.770, MCC: 0.580\n",
      "Fold 16 - RandomForest: Accuracy: 0.792, Precision: 0.821, Recall: 0.746, F1: 0.782, MCC: 0.587\n",
      "Fold 16 - KNN: Accuracy: 0.737, Precision: 0.707, Recall: 0.807, F1: 0.754, MCC: 0.478\n",
      "Fold 16 - MLP: Accuracy: 0.744, Precision: 0.776, Recall: 0.685, F1: 0.728, MCC: 0.492\n",
      "\n",
      "Processing fold 17/58 with 987 negative samples...\n",
      "Fold 17 - SVM: Accuracy: 0.792, Precision: 0.825, Recall: 0.741, F1: 0.781, MCC: 0.588\n",
      "Fold 17 - RandomForest: Accuracy: 0.777, Precision: 0.795, Recall: 0.746, F1: 0.770, MCC: 0.555\n",
      "Fold 17 - KNN: Accuracy: 0.744, Precision: 0.702, Recall: 0.848, F1: 0.768, MCC: 0.500\n",
      "Fold 17 - MLP: Accuracy: 0.747, Precision: 0.780, Recall: 0.685, F1: 0.730, MCC: 0.497\n",
      "\n",
      "Processing fold 18/58 with 987 negative samples...\n",
      "Fold 18 - SVM: Accuracy: 0.742, Precision: 0.754, Recall: 0.716, F1: 0.734, MCC: 0.484\n",
      "Fold 18 - RandomForest: Accuracy: 0.757, Precision: 0.776, Recall: 0.721, F1: 0.747, MCC: 0.515\n",
      "Fold 18 - KNN: Accuracy: 0.711, Precision: 0.677, Recall: 0.807, F1: 0.736, MCC: 0.431\n",
      "Fold 18 - MLP: Accuracy: 0.729, Precision: 0.739, Recall: 0.706, F1: 0.722, MCC: 0.459\n",
      "\n",
      "Processing fold 19/58 with 987 negative samples...\n",
      "Fold 19 - SVM: Accuracy: 0.759, Precision: 0.793, Recall: 0.701, F1: 0.744, MCC: 0.522\n",
      "Fold 19 - RandomForest: Accuracy: 0.744, Precision: 0.779, Recall: 0.680, F1: 0.726, MCC: 0.492\n",
      "Fold 19 - KNN: Accuracy: 0.732, Precision: 0.697, Recall: 0.817, F1: 0.752, MCC: 0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 19 - MLP: Accuracy: 0.742, Precision: 0.768, Recall: 0.690, F1: 0.727, MCC: 0.486\n",
      "\n",
      "Processing fold 20/58 with 987 negative samples...\n",
      "Fold 20 - SVM: Accuracy: 0.765, Precision: 0.795, Recall: 0.711, F1: 0.751, MCC: 0.532\n",
      "Fold 20 - RandomForest: Accuracy: 0.757, Precision: 0.773, Recall: 0.726, F1: 0.749, MCC: 0.515\n",
      "Fold 20 - KNN: Accuracy: 0.752, Precision: 0.726, Recall: 0.807, F1: 0.764, MCC: 0.507\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Option 1: Set the maximum CPU count (adjust \"8\" to your desired core count)\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = \"8\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "# --- Prepare indices for positive and negative samples ---\n",
    "# Assuming X and y are computed from the previous blocks\n",
    "# (X : combined feature matrix, y : labels with 1 for positive and 0 for negative)\n",
    "npos = np.sum(y == 1)\n",
    "nneg = np.sum(y == 0)\n",
    "\n",
    "print(f\"Total positive samples: {npos}\")\n",
    "print(f\"Total negative samples: {nneg}\")\n",
    "\n",
    "# The positive data are always included. For negatives, we split indices into k folds.\n",
    "# Shuffle all negative indices\n",
    "rng = np.random.default_rng(seed=42)\n",
    "neg_indices = np.arange(npos, npos + nneg)  # note: positive are from 0 to npos-1, negatives follow\n",
    "rng.shuffle(neg_indices)\n",
    "\n",
    "# Partition the negative indices into folds of size equal to npos\n",
    "folds = []\n",
    "num_folds = int(np.ceil(nneg / npos))\n",
    "for fold in range(num_folds):\n",
    "    start = fold * npos\n",
    "    end = start + npos\n",
    "    fold_neg_idx = neg_indices[start:end]\n",
    "    folds.append(fold_neg_idx)\n",
    "    \n",
    "print(f\"Created {len(folds)} folds for negatives (each of size ~{npos}).\")\n",
    "\n",
    "# --- Define classifiers ---\n",
    "classifiers = {\n",
    "    \"SVM\": SVC(probability=False, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"MLP\": MLPClassifier(random_state=42, max_iter=300)\n",
    "}\n",
    "\n",
    "# --- Result collection ---\n",
    "results = []\n",
    "\n",
    "# Iterate over each negative fold. For each fold, the positive samples remain the same.\n",
    "for i, neg_fold_idx in enumerate(folds, start=1):\n",
    "    print(f\"\\nProcessing fold {i}/{len(folds)} with {len(neg_fold_idx)} negative samples...\")\n",
    "    \n",
    "    # Create subset for the current fold:\n",
    "    # Positive indices: from 0 to npos-1 (they remain constant)\n",
    "    pos_idx = np.arange(npos)\n",
    "    # Combine indices: first positives then negatives from current fold\n",
    "    current_indices = np.concatenate((pos_idx, neg_fold_idx))\n",
    "    \n",
    "    X_fold = X[current_indices]\n",
    "    y_fold = y[current_indices]\n",
    "    \n",
    "    # Optionally shuffle the combined data set (which is balanced or nearly balanced)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_fold, y_fold, test_size=0.2, stratify=y_fold, random_state=42\n",
    "    )\n",
    "    \n",
    "    n_train = X_train.shape[0]\n",
    "    n_test  = X_test.shape[0]\n",
    "\n",
    "    X_train_flat = X_train.reshape(n_train, -1)\n",
    "    X_test_flat  = X_test.reshape(n_test,  -1)\n",
    "\n",
    "    for model_name, clf in classifiers.items():\n",
    "        # Train the classifier\n",
    "        clf.fit(X_train_flat, y_train)\n",
    "        # Predict on the test set\n",
    "        y_pred = clf.predict(X_test_flat)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        acc  = accuracy_score(y_test, y_pred)\n",
    "        pre  = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec  = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1   = f1_score(y_test, y_pred, zero_division=0)\n",
    "        mcc  = matthews_corrcoef(y_test, y_pred)\n",
    "        \n",
    "        # Append results for this fold and classifier\n",
    "        results.append({\n",
    "            \"Fold\": i,\n",
    "            \"Classifier\": model_name,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": pre,\n",
    "            \"Recall\": rec,\n",
    "            \"F1\": f1,\n",
    "            \"MCC\": mcc\n",
    "        })\n",
    "        print(f\"Fold {i} - {model_name}: Accuracy: {acc:.3f}, Precision: {pre:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}, MCC: {mcc:.3f}\")\n",
    "\n",
    "# Convert results to a DataFrame and display\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nOverall Results:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8982c9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Results:\n",
      "     Classifier  Accuracy  Precision  Recall     F1    MCC\n",
      "0           KNN     0.861      0.967   0.749  0.844  0.741\n",
      "1           MLP     0.925      0.928   0.922  0.925  0.849\n",
      "2  RandomForest     0.885      0.874   0.903  0.888  0.770\n",
      "3           SVM     0.925      0.899   0.958  0.927  0.851\n"
     ]
    }
   ],
   "source": [
    "# get average of the results. ignore the fold column\n",
    "results_df_avg = results_df.groupby('Classifier').mean().reset_index()\n",
    "results_df_avg = results_df_avg.drop(columns=['Fold'])\n",
    "\n",
    "results_df_avg = results_df_avg.round(3)\n",
    "print(\"\\nAverage Results:\")\n",
    "print(results_df_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7583284e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
